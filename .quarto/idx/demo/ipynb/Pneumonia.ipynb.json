{"title":"Projet de Machine Learning","markdown":{"yaml":{"title":"Projet de Machine Learning","author":"Guerzoniansus","date":"`r Sys.Date()`","execute":{"enabled":true},"format":{"html":{"code-fold":true}},"jupyter":"python3"},"headingText":"**PROJET QUARTO PRATIQUE**","containsRefs":false,"markdown":"\n\n\n\n\nLes examens radiographiques pulmonaires sont l'un des examens d'imagerie médicale les plus fréquents et les plus rentables disponibles. Cependant, le diagnostic clinique d'une radiographie thoracique peut être difficile et parfois plus difficile que le diagnostic par imagerie CT thoracique. Le manque de grands ensembles de données accessibles au public avec des annotations signifie qu'il est encore très difficile, voire impossible, d'obtenir une détection et un diagnostic assistés par ordinateur (CAD) cliniquement pertinents dans des sites médicaux du monde réel avec des radiographies pulmonaires.\n\nCet ensemble de données comprend 5216 images de train, 624 images de test et 16 images de validation.\n\n## **MODÈLE DE CLASSIFICATION : NORMAL ET PNEUMONIE**\n\n### **Compréhension de la tache**\n\nAvec cet ensemble de données, nous devons classer les images en deux classes (que la radiographie provienne d'un poumon normal ou d'un poumon atteint de pneumonie). Et ensuite, classez les poumons touchés en affection virale ou en affection bactérienne.\n\n#### Importation des packages nécessaires pour le code\n\n#### Mounting Google Drive\n\nCette partie est nécessaire pour obtenir le résultat du modèle pré-entraîné que nous avons créé.\n\n### **Data Importation**\n\nDans cette partie, nous obtiendrons notre base de données directement de Kaggle sans télécharger directement l'ensemble de données.\n\nEn effet, pour cette partie, vous devez importer le Kaggle Token qui vous sera fourni sous forme de *fichier json*. Vous devez importer ce fichier dans Colab, puis exécuter les codes ci-dessous.\nD'abord vous devez avoir un compte Kaggle. Ensuite télécharger votre Token Kaggle. En effet, en cliquant sur l'icone de votre profil Kaggle en haut à droite dans Kaggle (il s'agit généralement d'une tête de canard), vous clique sur l'icone paramètres et en bas vous devriez voir un bouton 'Create Token' ou 'Créer un jeton'. Vous cliquez dessus et vous télécharger le token Kaggle. Ensuite, vous l'importer sur Colab à partir de l'onglet fichier dans le menu vertical à gauche de l'écran.\n\nDownloading with the Chest-Xray-Pneumonia API in Kaggle\n\nUnzipping the downloaded file\n\n### **Data Visualization**\n\n### **Data Preprocessing**\n\nDans cette partie, nous allons écrire un code pour extraire les images du répertoire du jeu de données Kaggle.\n\nIci, nous allons redimensionner les images, les remodeler et les normaliser. Nous utilisons la méthode de normalisation standard pour les ensembles de données d'image qui divise chaque pixel par 255\n\nLe même processus précédent s'applique ici aussi et aussi pour l'ensemble de données de validation\n\nExtracting our files\n\nConversion des étiquettes dans un format plus compréhensible pour le modèle\n\n### **Model Creation**\n\n**CONVOLUTIONAL NEURAL NETWORK**\n\n\n\nIci, nous allons définir la structure de notre modèle et définir son architecture spécifique. Nous suivons l'architecture du modèle CNN de Yann Lecun pour la classification des images afin de déterminer le nombre de couches convolutives (et aussi les différents hyperparamètres de chaque couche convolutive), le nombre de couche Dense (pour la spécification du réseau de neurones entièrement connecté dans lequel les principales caractéristiques de chaque image seront traitées et extraites pour produire le résultat).\n\nNous modifions également l'architecture afin d'adapter nos données puisque cette base de données n'est pas si grande et n'a pas besoin d'un modèle complexe pour la traiter au risque de commettre un surajustement. Puis finalement, nous en sommes arrivés à ce modèle qui s'adapte bien à nos données et propose une descente des prédictions pour les images. Nous avons essayé plusieurs architectures et celle-ci semble être la meilleure\n\nNous avons un total de 104141 paramètres entraînables\n\nCompilation du modèle pour le montage. Ici, nous utilisons l'optimiseur Adam. C'est un excellent algorithme pour minimiser la perte et améliorer la précision du train comme l'algorithme de descente de gradient (SGD dans tensorflow). Les deux sont les optimiseurs standard utilisés dans les problèmes de classification d'images. Nous avons choisi l'optimiseur Adam (Adaptive Moment Estimation) en raison de sa convergence la plus rapide et du fait que l'algorithme adapte automatiquement le taux d'apprentissage qui l'amène plus rapidement au point de convergence. Et enfin, la gestion de la mémoire. De telles tâches peuvent être coûteuses en termes de consommation de mémoire. L'algorithme Adam simplifie le processus en utilisant\nmoyennes mobiles des gradients précédents pour mettre à jour les paramètres, ce qui lui permet de prendre en compte l'historique des gradients et de gérer plus efficacement les problèmes liés à la mémoire dans les réseaux de neurones profonds.\n\nNous avons également utilisé le \"binary_crossentropy loss function\"  car nous sommes dans le cas d'une classification binaire.\nLa métrique est la précision qui indique le pourcentage de prédictions vraies sur l'ensemble de données.\n\n#### Improving Model performance\n\nAprès avoir compilé et ajusté le modèle, nous pouvons voir que notre modèle apprend bien jusqu'à certains points où il va et vient et oscille. Ensuite, nous implémentons la méthode de rappel fournie par tensorflow qui est earlyStoppingCallback et nous spécifions le mode pour maximiser la précision de validation et et si cela va et vient pour prendre la meilleure précision de validation que le modèle a obtenue et prendre ces poids ou paramètres.\n\n**Saving Model**\n\nTo reload this model, you should first run the code 'drive.mount('/content/gdrive')'. Then you import the files in your drive especially in the file named MyDrive. And then you run the code 'model = tf.keras.models.load_model('/content/gdrive/MyDrive/Model.h5')'\n\n### **Model Evaluation and Testing**\n\nWe can see that our model overfits a little bit and that can be either be caused by the model complexity (the model is too complex and fits really quick to the train set and forgetting the test set) or the images' quality (the images are too blurry).\n\nNonetheless, we've got a train accuracy of 97,91% and 85,9 % for the test accuracy. Which means a total of 15% error in the test set. That is a descent result. An approach to solve the problem is Data augmentation which consists of increasing the train dataset and test dataset size.\n\nThis can either be done with *tf.image* or *tensorflow layers*. Therefore it's important not to increase the sizes too much because that could lead to underfitting. For memory purposes, this is not implemented\n\nPrediction for a single image in the train set\n\n## **CLASSIFYING VIRAL AND BACTERIAL PNEUMONIA**\n\nDans cet ensemble de données, nous avons également différents types de pneumonie (pneumonie virale et bactérienne). Cette partie est dédiée à la classification des images précédemment classées pneumonie en deux classes (Viral ou bactérien)\n\n### **Data Preparation**\n\nOn commence avec la préparation de la base de données\n\n### **Data Preprocessing**\n\nLe processus de ce code est en fait le même que les fonctions d'importation précédentes que nous avons définies précédemment.\n\n### **Data Visualization**\n\n### **Model Creation**\n\n**CONVOLUTIONAL NEURAL NETWORK**\n\nImportation de mesures supplémentaires et de packages de tracés\n\nModel architecture\n\nSome callbacks to ensure that the training is going well overall\n\nCSVLogger\n\nWe use the CSVLogger callback to get the loss and the metrics after the training. It is a CSV file.\n\nEarlyStopping\n\nLearningRateScheduler\n\nModel Training\n\nWe add some metrics to the compilation.\n\n**Saving model**\n\nTo reload this model, you should first run the code 'drive.mount('/content/gdrive')'. Then you import the Saved Models file in your drive especially in the file named MyDrive. And then you run the code 'pathology_model = tf.keras.models.load_model('/content/gdrive/MyDrive/Saved Models/Pathology_Model.h5')'\n\n### **Model Evaluation and Testing**\n\nHere, we have a train score of 95,38 % and a test score of 83.85 %. That mean we have a total of 17 % error on the test set.\n\nPrediction for a single image\n\n**VISUALIZING CONFUSION MATRIX**\n\nHere, we are going to look at the confusion matrix of the first classifier (Model).\n\nNous définissons le seuil à 0,5 pour voir à quoi ressemble la matrice de confusion. Le but de cette manœuvre est de réduire les erreurs de prédiction graves du modèle. Par exemple, si certains enfants ont une pneumonie et que le modèle prédit une situation normale. Cela peut être grave et avoir de lourdes conséquences. Nous essayons donc de réduire le nombre de ces erreurs de classification sans trop diminuer le nombre d'erreurs de classification des radiographies pulmonaires normales (images normales mais prédisant une pneumonie)\n\n**ROC Plots (Receiver Operating Characteristic)**\n\nSur la base de cette courbe ROC, puisque notre modèle est programmé de telle sorte que 1 signifie Pneumonie (Positif) et 0 signifie Normal (Négatif), nous essayons de réduire le nombre de faux négatifs. Cela signifie que nous essayons le nombre d'images de pneumonie qui sont prédites normales. Ensuite, pour réduire le taux de faux négatifs sans trop réduire le taux de vrais positifs, en se basant sur la courbe ROC, il faudrait prendre une valeur de seuil entre 0,5 et 0,4 pour réduire le taux de faux négatifs. Dans ce cas, il semble que prendre le seuil à 0,5 soit la meilleure chose possible. Nous prendrons donc le seuil à 0,5 dans le reste du travail pour \"modèle\"\n\nReducing the number of misclassification of bacterial pneumonia for the pathology model\n\nÉtant donné que les pneumonies bactériennes sont plus dangereuses que les virales en général, nous allons essayer de réduire le nombre de virus prédits mais réellement bactériens. Sur la base de la courbe ROC ci-dessus, un seuil de 0,6 semble être un bon compromis.\n\n**IMPLEMENTATING FUNCTION**\n\nWe define a final function which implements those models and return the result of all the previous classification.\n\nGenerating the image\n\nResizing, rescaling and normalizing\n\nPrediction function\n\n## ANOMALY DETECTION MODEL\n\nDans cette partie, nous allons classer les images en fonction du modèle de détection d'anomalies. Ce modèle utilise un encodeur qui prend les images de pneumonie en entrée et utilise des couches convolutives pour extraire les principales caractéristiques de l'image afin de faire la différence entre les images de pneumonie et les images de poumons normaux. Le décodeur prend les caractéristiques et génère une image qui ressemble à l'image d'entrée et apprend comment sont les images de pneumonie. Il apprend les différentes caractéristiques inhérentes aux images de pneumonie. Et puis face à des images radiographiques normales, la perte devrait être plus importante et cela signifie que la configuration des images normales est différente de la configuration des images radiographiques. C'est ainsi qu'il procède pour faire la classification\n\n### Data preparation\n\nLoading the data. The same process as the other codes for importation\n\n### Model Creation\n\nWe create a class which inherits from the Model class in tensorflow.keras. That class contains the encoder, the decoder and returns the decoded image of the input.\n\n### Model training\n\nThe model will be trained only with the pneumonia images on the encoder in order to extract the maximum information from the\n\nSaving the model\n\nLoading the model\n\n### The threshold value\n\nSo, we get the threshold value and the number of pneumonia images that we've lost meaning we've classified as normal\n\nThen, if the loss is less than the threshold, the image will be classified as pneumonia. Else, it will be classified as normal.\n\nAccuracy of the prediction\n\nTesting\n","srcMarkdownNoYaml":"\n\n# **PROJET QUARTO PRATIQUE**\n\n\n\nLes examens radiographiques pulmonaires sont l'un des examens d'imagerie médicale les plus fréquents et les plus rentables disponibles. Cependant, le diagnostic clinique d'une radiographie thoracique peut être difficile et parfois plus difficile que le diagnostic par imagerie CT thoracique. Le manque de grands ensembles de données accessibles au public avec des annotations signifie qu'il est encore très difficile, voire impossible, d'obtenir une détection et un diagnostic assistés par ordinateur (CAD) cliniquement pertinents dans des sites médicaux du monde réel avec des radiographies pulmonaires.\n\nCet ensemble de données comprend 5216 images de train, 624 images de test et 16 images de validation.\n\n## **MODÈLE DE CLASSIFICATION : NORMAL ET PNEUMONIE**\n\n### **Compréhension de la tache**\n\nAvec cet ensemble de données, nous devons classer les images en deux classes (que la radiographie provienne d'un poumon normal ou d'un poumon atteint de pneumonie). Et ensuite, classez les poumons touchés en affection virale ou en affection bactérienne.\n\n#### Importation des packages nécessaires pour le code\n\n#### Mounting Google Drive\n\nCette partie est nécessaire pour obtenir le résultat du modèle pré-entraîné que nous avons créé.\n\n### **Data Importation**\n\nDans cette partie, nous obtiendrons notre base de données directement de Kaggle sans télécharger directement l'ensemble de données.\n\nEn effet, pour cette partie, vous devez importer le Kaggle Token qui vous sera fourni sous forme de *fichier json*. Vous devez importer ce fichier dans Colab, puis exécuter les codes ci-dessous.\nD'abord vous devez avoir un compte Kaggle. Ensuite télécharger votre Token Kaggle. En effet, en cliquant sur l'icone de votre profil Kaggle en haut à droite dans Kaggle (il s'agit généralement d'une tête de canard), vous clique sur l'icone paramètres et en bas vous devriez voir un bouton 'Create Token' ou 'Créer un jeton'. Vous cliquez dessus et vous télécharger le token Kaggle. Ensuite, vous l'importer sur Colab à partir de l'onglet fichier dans le menu vertical à gauche de l'écran.\n\nDownloading with the Chest-Xray-Pneumonia API in Kaggle\n\nUnzipping the downloaded file\n\n### **Data Visualization**\n\n### **Data Preprocessing**\n\nDans cette partie, nous allons écrire un code pour extraire les images du répertoire du jeu de données Kaggle.\n\nIci, nous allons redimensionner les images, les remodeler et les normaliser. Nous utilisons la méthode de normalisation standard pour les ensembles de données d'image qui divise chaque pixel par 255\n\nLe même processus précédent s'applique ici aussi et aussi pour l'ensemble de données de validation\n\nExtracting our files\n\nConversion des étiquettes dans un format plus compréhensible pour le modèle\n\n### **Model Creation**\n\n**CONVOLUTIONAL NEURAL NETWORK**\n\n\n\nIci, nous allons définir la structure de notre modèle et définir son architecture spécifique. Nous suivons l'architecture du modèle CNN de Yann Lecun pour la classification des images afin de déterminer le nombre de couches convolutives (et aussi les différents hyperparamètres de chaque couche convolutive), le nombre de couche Dense (pour la spécification du réseau de neurones entièrement connecté dans lequel les principales caractéristiques de chaque image seront traitées et extraites pour produire le résultat).\n\nNous modifions également l'architecture afin d'adapter nos données puisque cette base de données n'est pas si grande et n'a pas besoin d'un modèle complexe pour la traiter au risque de commettre un surajustement. Puis finalement, nous en sommes arrivés à ce modèle qui s'adapte bien à nos données et propose une descente des prédictions pour les images. Nous avons essayé plusieurs architectures et celle-ci semble être la meilleure\n\nNous avons un total de 104141 paramètres entraînables\n\nCompilation du modèle pour le montage. Ici, nous utilisons l'optimiseur Adam. C'est un excellent algorithme pour minimiser la perte et améliorer la précision du train comme l'algorithme de descente de gradient (SGD dans tensorflow). Les deux sont les optimiseurs standard utilisés dans les problèmes de classification d'images. Nous avons choisi l'optimiseur Adam (Adaptive Moment Estimation) en raison de sa convergence la plus rapide et du fait que l'algorithme adapte automatiquement le taux d'apprentissage qui l'amène plus rapidement au point de convergence. Et enfin, la gestion de la mémoire. De telles tâches peuvent être coûteuses en termes de consommation de mémoire. L'algorithme Adam simplifie le processus en utilisant\nmoyennes mobiles des gradients précédents pour mettre à jour les paramètres, ce qui lui permet de prendre en compte l'historique des gradients et de gérer plus efficacement les problèmes liés à la mémoire dans les réseaux de neurones profonds.\n\nNous avons également utilisé le \"binary_crossentropy loss function\"  car nous sommes dans le cas d'une classification binaire.\nLa métrique est la précision qui indique le pourcentage de prédictions vraies sur l'ensemble de données.\n\n#### Improving Model performance\n\nAprès avoir compilé et ajusté le modèle, nous pouvons voir que notre modèle apprend bien jusqu'à certains points où il va et vient et oscille. Ensuite, nous implémentons la méthode de rappel fournie par tensorflow qui est earlyStoppingCallback et nous spécifions le mode pour maximiser la précision de validation et et si cela va et vient pour prendre la meilleure précision de validation que le modèle a obtenue et prendre ces poids ou paramètres.\n\n**Saving Model**\n\nTo reload this model, you should first run the code 'drive.mount('/content/gdrive')'. Then you import the files in your drive especially in the file named MyDrive. And then you run the code 'model = tf.keras.models.load_model('/content/gdrive/MyDrive/Model.h5')'\n\n### **Model Evaluation and Testing**\n\nWe can see that our model overfits a little bit and that can be either be caused by the model complexity (the model is too complex and fits really quick to the train set and forgetting the test set) or the images' quality (the images are too blurry).\n\nNonetheless, we've got a train accuracy of 97,91% and 85,9 % for the test accuracy. Which means a total of 15% error in the test set. That is a descent result. An approach to solve the problem is Data augmentation which consists of increasing the train dataset and test dataset size.\n\nThis can either be done with *tf.image* or *tensorflow layers*. Therefore it's important not to increase the sizes too much because that could lead to underfitting. For memory purposes, this is not implemented\n\nPrediction for a single image in the train set\n\n## **CLASSIFYING VIRAL AND BACTERIAL PNEUMONIA**\n\nDans cet ensemble de données, nous avons également différents types de pneumonie (pneumonie virale et bactérienne). Cette partie est dédiée à la classification des images précédemment classées pneumonie en deux classes (Viral ou bactérien)\n\n### **Data Preparation**\n\nOn commence avec la préparation de la base de données\n\n### **Data Preprocessing**\n\nLe processus de ce code est en fait le même que les fonctions d'importation précédentes que nous avons définies précédemment.\n\n### **Data Visualization**\n\n### **Model Creation**\n\n**CONVOLUTIONAL NEURAL NETWORK**\n\nImportation de mesures supplémentaires et de packages de tracés\n\nModel architecture\n\nSome callbacks to ensure that the training is going well overall\n\nCSVLogger\n\nWe use the CSVLogger callback to get the loss and the metrics after the training. It is a CSV file.\n\nEarlyStopping\n\nLearningRateScheduler\n\nModel Training\n\nWe add some metrics to the compilation.\n\n**Saving model**\n\nTo reload this model, you should first run the code 'drive.mount('/content/gdrive')'. Then you import the Saved Models file in your drive especially in the file named MyDrive. And then you run the code 'pathology_model = tf.keras.models.load_model('/content/gdrive/MyDrive/Saved Models/Pathology_Model.h5')'\n\n### **Model Evaluation and Testing**\n\nHere, we have a train score of 95,38 % and a test score of 83.85 %. That mean we have a total of 17 % error on the test set.\n\nPrediction for a single image\n\n**VISUALIZING CONFUSION MATRIX**\n\nHere, we are going to look at the confusion matrix of the first classifier (Model).\n\nNous définissons le seuil à 0,5 pour voir à quoi ressemble la matrice de confusion. Le but de cette manœuvre est de réduire les erreurs de prédiction graves du modèle. Par exemple, si certains enfants ont une pneumonie et que le modèle prédit une situation normale. Cela peut être grave et avoir de lourdes conséquences. Nous essayons donc de réduire le nombre de ces erreurs de classification sans trop diminuer le nombre d'erreurs de classification des radiographies pulmonaires normales (images normales mais prédisant une pneumonie)\n\n**ROC Plots (Receiver Operating Characteristic)**\n\nSur la base de cette courbe ROC, puisque notre modèle est programmé de telle sorte que 1 signifie Pneumonie (Positif) et 0 signifie Normal (Négatif), nous essayons de réduire le nombre de faux négatifs. Cela signifie que nous essayons le nombre d'images de pneumonie qui sont prédites normales. Ensuite, pour réduire le taux de faux négatifs sans trop réduire le taux de vrais positifs, en se basant sur la courbe ROC, il faudrait prendre une valeur de seuil entre 0,5 et 0,4 pour réduire le taux de faux négatifs. Dans ce cas, il semble que prendre le seuil à 0,5 soit la meilleure chose possible. Nous prendrons donc le seuil à 0,5 dans le reste du travail pour \"modèle\"\n\nReducing the number of misclassification of bacterial pneumonia for the pathology model\n\nÉtant donné que les pneumonies bactériennes sont plus dangereuses que les virales en général, nous allons essayer de réduire le nombre de virus prédits mais réellement bactériens. Sur la base de la courbe ROC ci-dessus, un seuil de 0,6 semble être un bon compromis.\n\n**IMPLEMENTATING FUNCTION**\n\nWe define a final function which implements those models and return the result of all the previous classification.\n\nGenerating the image\n\nResizing, rescaling and normalizing\n\nPrediction function\n\n## ANOMALY DETECTION MODEL\n\nDans cette partie, nous allons classer les images en fonction du modèle de détection d'anomalies. Ce modèle utilise un encodeur qui prend les images de pneumonie en entrée et utilise des couches convolutives pour extraire les principales caractéristiques de l'image afin de faire la différence entre les images de pneumonie et les images de poumons normaux. Le décodeur prend les caractéristiques et génère une image qui ressemble à l'image d'entrée et apprend comment sont les images de pneumonie. Il apprend les différentes caractéristiques inhérentes aux images de pneumonie. Et puis face à des images radiographiques normales, la perte devrait être plus importante et cela signifie que la configuration des images normales est différente de la configuration des images radiographiques. C'est ainsi qu'il procède pour faire la classification\n\n### Data preparation\n\nLoading the data. The same process as the other codes for importation\n\n### Model Creation\n\nWe create a class which inherits from the Model class in tensorflow.keras. That class contains the encoder, the decoder and returns the decoded image of the input.\n\n### Model training\n\nThe model will be trained only with the pneumonia images on the encoder in order to extract the maximum information from the\n\nSaving the model\n\nLoading the model\n\n### The threshold value\n\nSo, we get the threshold value and the number of pneumonia images that we've lost meaning we've classified as normal\n\nThen, if the loss is less than the threshold, the image will be classified as pneumonia. Else, it will be classified as normal.\n\nAccuracy of the prediction\n\nTesting\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":true,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../css/styles.css"],"toc":true,"output-file":"Pneumonia.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.554","theme":{"light":"flatly","dark":"darkly"},"fontsize":"18px","title":"Projet de Machine Learning","author":"Guerzoniansus","date":"`r Sys.Date()`","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}